# -*- coding: utf-8 -*-
"""WatermarksCNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CyMPRlOHCaUwXKVUni7r2tAFJyDWVx-K
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd "/content/drive/MyDrive/WaterMarkDetector/"
!ls

import os
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from PIL import Image
import numpy as np

# Directorio de los datos de entrenamiento
train_dir = 'watermarks/train'
validation_dir = 'watermarks/validation'

# Generador de datos de entrenamiento
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,  # Rango de rotación aleatoria de hasta 20 grados
    zoom_range=0.2,  # Rango de zoom aleatorio
    width_shift_range=0.2,  # Rango de desplazamiento horizontal aleatorio
    height_shift_range=0.2,  # Rango de desplazamiento vertical aleatorio
    horizontal_flip=True,  # Volteo horizontal aleatorio
    vertical_flip=True  # Volteo vertical aleatorio
)

validation_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,  # Rango de rotación aleatoria de hasta 20 grados
    zoom_range=0.2,  # Rango de zoom aleatorio
    width_shift_range=0.2,  # Rango de desplazamiento horizontal aleatorio
    height_shift_range=0.2,  # Rango de desplazamiento vertical aleatorio
    horizontal_flip=True,  # Volteo horizontal aleatorio
    vertical_flip=True  # Volteo vertical aleatorio
)

# Crear generador de datos de entrenamiento
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(100, 100),
    batch_size=32,
    class_mode='binary'
)

# Crear generador de datos de validación
validation_generator = validation_datagen.flow_from_directory(
    validation_dir,
    target_size=(100, 100),
    batch_size=32,
    class_mode='binary'
)


def safe_image_generator(generator):
    while True:
        try:
            batch_x, batch_y = next(generator)
            labels = []
            for i in range(len(batch_x)):
                if batch_x[i] is None:
                    continue
                labels.append(batch_y[i])
            yield batch_x, np.array(labels)  # Devolver un array de etiquetas
        except Exception as e:
            print(f"Error generating batch: {e}")
            if 'image file is truncated' in str(e):
                print(f"Skipping image: {generator.filenames[generator.batch_index]}")
            continue

# Crear el generador de imágenes de entrenamiento seguro
train_safe_generator = safe_image_generator(train_generator)

# Crear el generador de imágenes de validación seguro
validation_safe_generator = safe_image_generator(validation_generator)

# Obtener un solo lote de imágenes y etiquetas
batch_x, batch_y = next(train_safe_generator)

# Imprimir la forma de batch_x y batch_y
print(batch_x.shape)
print(batch_y.shape)

# Visualizar las primeras 10 imágenes
plt.figure()
f, axarr = plt.subplots(1, 10, figsize=(30, 4))
for i in range(10):
    axarr[i].imshow(batch_x[i])
    axarr[i].axis("off")
    axarr[i].set_title(batch_y[i])

import os
import numpy as np
from PIL import Image
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Crear el modelo CNN
model = Sequential([
    # Capa convolucional con 32 filtros de 3x3 y función de activación ReLU
    Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)),

    # Capa de pooling para reducir las dimensiones de la salida
    MaxPooling2D((2, 2)),

    # Segunda capa convolucional con 64 filtros de 3x3 y función de activación ReLU
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),

    # Tercera capa convolucional con 128 filtros de 3x3 y función de activación ReLU
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),  # Capa de pooling

    # Aplanar la salida para pasarla a capas densas
    Flatten(),
    # Capa densa con 512 neuronas y función de activación ReLU
    Dense(512, activation='relu'),
    # Capa de salida con 1 neurona y función de activación sigmoide para clasificación binaria
    Dense(1, activation='sigmoid')
])

# Compilar el modelo
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])


# Entrenamiento del modelo
history = model.fit(
    train_safe_generator,  # Usar el generador de datos de entrenamiento seguro
    epochs=10,  # Número de épocas de entrenamiento
    steps_per_epoch=len(train_generator),  # Número de pasos por época (tamaño del generador de datos de entrenamiento)
    validation_data=validation_safe_generator,  # Usar el generador de datos de validación seguro
    validation_steps=len(validation_generator)  # Número de pasos de validación por época (tamaño del generador de datos de validación)
)

# Graficar resultados
acc = history.history['accuracy']
loss = history.history['loss']

epochs = range(1, len(acc) + 1)

plt.plot(epochs, acc, 'bo', label='train accuracy')
plt.title('train acc')
plt.legend()

plt.figure()

plt.plot(epochs, loss, 'bo', label='training loss')
plt.title('train loss')
plt.legend()

# Definir el nombre del archivo donde se guardará el modelo
model_filename = 'modelo_cnn_watermarks1.h5'

# Guardar el modelo en el archivo especificado
model.save(model_filename)

# Verificar si el archivo se ha guardado correctamente
if os.path.exists(model_filename):
    print(f"Modelo guardado correctamente en {model_filename}")
else:
    print("Error al guardar el modelo")

import os

# Definir el nombre del archivo donde se guardará el modelo
model_filename = 'modelo_cnn_watermarks1.h5'

# Obtener la ruta completa al archivo
full_path = os.path.abspath(model_filename)

print(f"Modelo guardado en: {full_path}")