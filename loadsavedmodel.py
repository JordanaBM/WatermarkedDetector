# -*- coding: utf-8 -*-
"""LoadSavedModel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16yew1HL4VN3rXdzOj9QkVRo0J1sa2tXh
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd "/content/drive/MyDrive/WaterMarkDetector"
!ls

import requests
from PIL import Image
import numpy as np
from tensorflow.keras.models import load_model
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
import os
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Directorio de los datos de prueba
test_dir = 'watermarks/test'

# Cargar el modelo desde el archivo
#model = load_model('modelo_cnn_watermarks1.h5')
model = load_model('modelo_optimizado_cnn_watermarks.h5')


# Crear generador de datos de prueba
test_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,  # Rango de rotación aleatoria de hasta 20 grados
    horizontal_flip=True,  # Volteo horizontal aleatorio
    vertical_flip=True  # Volteo vertical aleatorio
    )

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(100, 100),
    batch_size=32,
    class_mode='binary',
    shuffle=True
)

# Evaluar el modelo en el conjunto de prueba
loss, accuracy = model.evaluate(test_generator, steps=len(test_generator))

print(f'Loss en el conjunto de prueba: {loss}')
print(f'Accuracy en el conjunto de prueba: {accuracy}')

import matplotlib.pyplot as plt

# Definir las listas vacías para las etiquetas y predicciones
labels = []
predictions = []

for i in range(0, 100, 10):  # Incrementar de 10 en 10 hasta llegar a 100
    # Crear una figura con 10 subplots
    fig, axs = plt.subplots(2, 5, figsize=(20, 8))

    # Iterar sobre cada subplot y mostrar una imagen con su predicción
    for j in range(10):
        # Obtener la imagen y la etiqueta
        image = test_generator[i + j][0][0]  # Obtenemos el primer (y único) elemento del lote
        label = test_generator[i + j][1][0]

        # Obtener la predicción del modelo
        prediction = model.predict(np.expand_dims(image, axis=0), verbose=0)[0][0]
        class_name = 'watermark' if prediction >= 0.5 else 'no watermark'
        labels.append(label)
        predictions.append(1 if prediction >= 0.5 else 0)


        # Mostrar la imagen con su predicción en el subplot correspondiente
        row = j // 5  # Calcular la fila del subplot
        col = j % 5  # Calcular la columna del subplot
        axs[row, col].imshow(image)
        axs[row, col].axis('off')
        axs[row, col].set_title(f'Predicción: {class_name}, Real: {"watermark" if label == 1 else "no watermark"}')

    plt.tight_layout()
    plt.show()

# Crear la matriz de confusión
conf_matrix = confusion_matrix(labels, predictions)

# Definir los nombres de las clases
class_names = ['No Watermark', 'Watermark']

# Crear un dataframe de la matriz de confusión para mostrar los nombres de las clases
conf_matrix_df = pd.DataFrame(conf_matrix, index=class_names, columns=class_names)

# Crear el heatmap de la matriz de confusión
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix_df, annot=True, fmt="d", cmap="Blues")
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

# Calcular True Positives (TPs), True Negatives (TNs), False Positives (FPs), False Negatives (FNs)
TPs = conf_matrix[0, 0]
TNs = conf_matrix[1, 1]
FPs = conf_matrix[1, 0]
FNs = conf_matrix[0, 1]

# Calcular True Positive Rate (TPR), False Positive Rate (FPR), Precision
TPR = TPs / (TPs + FNs)
FPR = FPs / (FPs + TNs)
Precision = TPs / (TPs + FPs)

# Imprimir métricas
print("True Positives (TPs) - not-watermarked:", TPs)
print("True Negatives (TNs) - watermarked:", TNs)
print("False Positives (FPs) - watermarked predicted as not-watermarked:", FPs)
print("False Negatives (FNs) - not-watermarked predicted as watermarked:", FNs)
print("True Positive Rate (TPR) - not-watermarked:", TPR)
print("False Positive Rate (FPR) - watermarked:", FPR)
print("Precision:", Precision)

import requests
import numpy as np
from PIL import Image
from tensorflow.keras.models import load_model
import matplotlib.pyplot as plt

# Array de URLs de las imágenes
urls = [
    "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRZuT2dYDb5gH6svuwc-AMthj9O4j231cgeMDFOSNLnYg&s",
    "https://img.freepik.com/foto-gratis/paisaje-forestal_71767-127.jpg",
    "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSa3k5CNJlgvybl89u3GVSTUM_DPACg8UgUgrs_Iu_gKw&s",
    "https://www.lukecollinsphotography.com/wp-content/uploads/2018/10/should-you-watermark-images-5.jpg",
    "https://upload.wikimedia.org/wikipedia/commons/c/c2/Vulpes_vulpes_2.jpg"
]

# Cargar el modelo pre-entrenado
model = load_model('modelo_cnn_watermarks1.h5', compile=False)

# Iterar sobre las URLs
for i, url in enumerate(urls, start=1):
    # Descargar la imagen de Internet
    response = requests.get(url)
    with open('watermark_image.jpg', 'wb') as f:
        f.write(response.content)

    # Procesar la imagen
    imagen = Image.open('watermark_image.jpg')
    target_size = (100, 100)
    imagen_redimensionada = imagen.resize(target_size)
    imagen_array = np.array(imagen_redimensionada) / 255.0  # Normalizar los valores de píxeles
    imagen_final = np.expand_dims(imagen_array, axis=0)  # Agregar dimensión adicional para el batch

    # Realizar la predicción sin mostrar mensajes de progreso
    prediccion = model.predict(imagen_final, verbose=0)
    predict_class = (prediccion > 0.4).astype("int32")

    # Imprimir la predicción con la imagen
    plt.subplot(1, 3, i % 3 + 1)
    plt.imshow(imagen_redimensionada)

    if predict_class[0][0] == 1:
        plt.title('Con marca de agua')
    else:
        plt.title('Sin marca de agua')
    plt.axis('off')

    # Imprimir las imágenes en grupos de tres
    if i % 3 == 0:
        plt.show()
        plt.figure()

# Si queda alguna imagen por mostrar
if len(urls) % 3 != 0:
    plt.show()